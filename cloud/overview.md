---
layout: default
---

# Overview

## Video introduction

<iframe width="373" height="210" src="http://www.youtube.com/embed/71MJSFDPHb0?rel=0&amp;start=357&amp;end=430&amp;autoplay=0&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>
(Research IT's Patrick Schmitz summarizes Cloud Computing Support, from the [Berkeley Research Computing Town Hall meeting on May 28, 2015](http://research-it.berkeley.edu/blog/15/06/12/town-hall-launch-brc-faculty-computing-allowance).)

## About the Cloud Consulting services

Berkeley Research Computing (BRC) Cloud Consulting services identify cloud resources that are well-matched to the needs of UC Berkeley researchers, and facilitate access to those resources.

Cloud resources may be provided by external vendors (such as [Amazon](http://aws.amazon.com/), [Google](https://cloud.google.com/), or [Microsoft](https://azure.microsoft.com/en-us/)), national centers (such as [XSEDE](https://www.xsede.org/) or [NERSC](https://www.nersc.gov/)), or by BRC itself. There is no cost to researchers for these consulting services, within manageable limits.

Here's what you can expect from the BRC Cloud consultants:

#### Engage with researchers to match requirements with appropriate cloud resources

* Review computing and data requirements for research uses to identify where those uses translate well to cloud resources.
* Assist researchers in identifying the set of cloud services that efficiently and effectively address their computational and storage requirements.
* Simplify the use of commonly used software stacks across multiple cloud platforms.
* Provide documentation, training, guidance, and referrals for translating commonly-encountered computing requirements into patterns suited for efficient and cost-effective use of cloud resources for instruction and research.
* Help researchers working with sensitive data identify whether and how they can appropriately work with that data on cloud resources.

#### Facilitate access to cloud resources

* Assist researchers in obtaining provider grants.
* Provide support for incorporating cloud computing resource costs into funding proposals.
* Publish documentation and provide consulting to help researchers benefit from campus contracts and guidelines.
* Assist researchers to manage costs and/or transfer times for moving data to and from cloud resources.

#### Automate cloud provisioning

* Provide automated provisioning scripts, ‘best practices’ examples, documentation, and consulting to support integrations with cloud providers that address specific types of campus research and instruction.
* Allow PIs to conveniently manage, and delegate the management of, cloud provider accounts to postdocs, graduate student researchers (GSRs), or others.
* Allow instructors to conveniently manage, and delegate the management of, cloud provider accounts to graduate student instructors (GSIs) or others.
* Help PIs and instructors to control and gain clearer insights into cloud costs via billing alerts, mechanisms to limit unintended overages, and best practices documentation.

### Representative campus use cases

The following use cases represent some of the ways that UC Berkeley campus researchers are using, or have told us they would benefit from use of, cloud consulting support, as well as (future) support for flexible computing options and mobility of computing and data:

* **Center for Computational Biology / QB3**: Robert Tunney, a PhD student in Lior Pachter’s Lab, is working on streamlined identification of patterns (motifs) of nucleotides or amino acids with potential biological significance. The lab has implemented a parallelized version of the MEME algorithm on the Apache Spark engine, initially with small datasets. They plan to test this implementation at larger scale on an Amazon Web Services (AWS) cluster, with the goal of achieving faster run times; however, they don't have a way to pay for cloud computing with campus billing systems. BRC will facilitate access to and billing for AWS.
* **Institute of Transportation Studies**: The Connected Corridors program uses a data- and model-driven approach to develop real-time decision support for integrated transportation corridor management for the State of California, combining contributions from Professors Alexandre M. Bayen (PI, EECS & CEE), Roberto Horowitz (ME), Adib Kanafani (CEE), Alexey Pozdnukhov (CEE), Alexander Skabardonis (CEE), and Pravin Varaiya (EECS). The program's ever-increasing computing requirements, aging high-maintenance hardware, staff turnover, and constrained funding posed serious threats to progress. The move to cloud computing, including a cluster of Apache Cassandra NoSQL databases on hosts in Amazon’s EC2 cloud, will enable the program to better manage costs while increasing on-demand peak computing performance. Use of cloud computing is a key component of a $5M competitive grant proposal to ARPA-E (Department of Energy), in cooperation with LBNL, for new smart cities work in energy and transportation. BRC will provide consulting and guidance in the form of best practices, planning, research data management, technical training for research support staff, and assistance navigating University and cloud vendor business processes.
* **Social Sciences & Computer Sciences collaboration**: Tech4Measurement is a mobile device- & cloud-based research platform collaboration across two broad domains, led by BIDS Fellow Dav Clark and CEGA Director Temina Madon in the Social Sciences, and Matt Podolsky in Computer Sciences. Their goal is to improve the usage of sensor, mobile, and remote-sensing technology to measure social phenomena. The Mezuri Data Platform (in development) leverages Google’s public cloud to combine data collection technologies; data management and processing; and a web-based front end for analyzing, visualizing, and sharing data. BRC will facilitate provisioning of required support for Google’s public cloud, with emphasis on billing and cost control, data security, and compliance with IRB research protocols.
* **School of Public Health (instructional)**: Professor Lexin Li’s course introduces key approaches, tools, and techniques to public health graduate students, including data mining; machine learning methods; analysis of characteristically messy “real-world” data; and parallel processing using Hadoop and Spark. Neither the School of Public Health nor its Biostatistics Division maintains computing resources capable of supporting a data science course in their domains. The faculty would like to leverage vendor subsidies available from public cloud providers to run the computational infrastructure for their courses. BRC will accelerate access to vendor subsidies and provisioning of public cloud resources in teaching and training environments, and provide continuity for graduate students who wish to continue using cloud computing platforms in research contexts.
* **Linguistics**: Keith Johnson, Director of the Phonology Lab, studies language sound systems and speech production and perception. Johnson, along with Linguistics staff member Ronald Sprouse, maintain the Berkeley Phonetics Machine, a software toolkit for phonetics and phonology research and teaching at Berkeley and other institutions. When performing analysis that requires more memory or CPU than available on a laptop or workstation, the time and cost required to change software packaging to suit an HPC environment presents a barrier. BRC’s user-supplied virtual machine images will allow these researchers to leverage BRC managed computational resources without requiring changes to code or software installation procedures. Running virtual machine images in the cloud is costly for sustained use, so providing this capability in the HPC environment provides a lower cost option and more flexible means to make use of the Faculty Compute Allowance. 
* **Neuroscience**: BIDS Fellow Fatma Imamoglu, a Postdoc in Jack Gallant’s lab, is studying language and music processing in the human brain using functional magnetic resonance imaging (fMRI), which measures brain activity via blood flow. The lab’s work is constrained by several aspects of its current computing cluster: storage space is already limited and needs are projected to grow rapidly over the next 5 years; matrix manipulation is restricted to being run on single nodes, while per-node memory is insufficient to efficiently run some algorithms; and bandwidth limits constrain simultaneous work by researchers as well as the use of higher-resolution fMRI images. Data privacy constraints prevent analyzing this data unencrypted in the cloud. Moving some work onto other computational platforms may help -- for instance, by using Apache Spark for manipulating multiple matrices across many nodes and using higher-memory nodes. BRC’s support for Hadoop and Spark will allow “bursting” beyond local resources to institutionally managed nodes running a compatible software stack; this provides a means to balance the trade-offs between better performance versus the convenience of software running on campus-managed infrastructure.
* **Psychology**: Jessica Hamrick, a PhD student in Tom Griffiths’ Lab, develops high-level models of human cognition, visualizing models for mental rotation of 2D and 3D objects for researchers and students to explore iteratively. These visualizations are generated by computational models too demanding to run in a hosted notebook environment or on a typical laptop computer, but most traditional HPC clusters don’t accommodate interactive access via external web browsers. Cloud computing might be able to provide sufficient computational resources and interactive access, but only at a prohibitive cost. BRC’s support of interactive, browser-based IPython notebooks that offer campus-authenticated access to HPC resources will broadly increase access to computing resources for Hamrick’s and Griffiths’ teaching and research communities, which have historically been underrepresented in traditional HPC environments.
* **Molecular and Cell Biology and Chemistr**y: Tiago Barros is a Postdoc and Research Specialist in John Kuriyan’s Lab. His biomedical research includes investigation of proteins involved in bacterial DNA replication and cell signaling. Molecular dynamics simulations, which simulate at atomic detail the motions of proteins of interest over time, play a crucial role. These calculations simulate systems comprising up to half a million atoms and require specialized software packages running on HPC clusters or GPUs.  Running and optimizing these calculations includes testing at scale, which is not possible on the lab’s current resources without acquiring expensive hardware that would remain unused most of the time, i.e., when not engaged in either at-scale testing or production runs. Using the cloud allows allocating resources on demand, but adds complexity and cost for parts of the workflow requiring higher performance data access. BRC’s consultation on planning for use of portable environments will ensure that software can run with little or no modification, in a performant manner, in multiple computational environments (workstation, HPC/Savio, public cloud). Consulting will also address movement of data between systems, and best practices for cloud storage performance and cost-containment. The resultant flexibility will support local development, right-sizing in the cloud for at-scale testing, and cost-containment on institutionally-managed hardware.
* **Goldman School of Public Policy**: Professor Amy Lerman’s recent research asks: What are the political implications of violent crime? For example, does voter turnout respond to increases in local violence? Analysis of the full datasets used in this research is limited by the size of currently available workstations. The cost and skills required to build and manage a cluster exceeds the time, money, and training of individual research groups or the GSPP itself. The complexity of using the cloud for computing presents challenges in balancing data access, performance, and persistence. Where possible, these groups would prefer to continue to use current workstation resources for development and testing on subsets of their research problems. BRC consultants will help these researchers incorporate best practices to facilitate mobility of computation, supporting their workflows to ensure data is available with good access performance across environments,  and permitting future use of additional, larger-scale computational resources.
* **Law and Economics**: Professor Justin McCrary explores the impacts of stock exchange and governmental policy changes on securities trading behavior. This work analyzes large datasets of millisecond-level trades and quotes. Analyses of three days’ activity can take two days to run; mistakes necessitate re-runs. He would like to adapt existing software to run on BRC resources, “bursting” into the public cloud when needed, while accounting for cloud data transfer cost models to avoid unnecessary charges when working with large datasets. He would also like to teach on the same dataset using public cloud computational resources (e.g., with educational grants). BRC will provide consulting in the form of planning and best practices to adapt existing software to make effective use of both the HPC and cloud environments, and to help manage costs such as data egress charges from the cloud. Portable environments would help to enable reproducibility, simplify long-term management of the analytics stack, and ensure compatibility across computing resources supported by the BRC program.



### Get started!

We welcome Berkeley faculty, staff, postdocs, and grad students at all levels of expertise to schedule time with our consultants, even at the very earliest stages of your research, for any size computational requirements you may have. Our standard consulting services are free of charge.

Please email us at the following address, and include the following in your request: a brief description of your project, a concise overview of the software and data you're using, and a summary of what stage you are at in your research process.

[research-it@berkeley.edu](mailto:research-it@berkeley.edu)

